# ğŸ¯ Quick Reference: Voice Processor API Improvements

## For Better Speech-to-Text APIs (Future Migration)

### Option 1: Google Cloud Speech-to-Text â­ Recommended

```javascript
// Installation
npm install @google-cloud/speech

// Implementation
import speech from '@google-cloud/speech'

const client = new speech.SpeechClient({
  keyFilename: 'path/to/service-account-key.json'
})

const config = {
  encoding: 'WEBM_OPUS',
  sampleRateHertz: 48000,
  languageCode: 'hi-IN',
  alternativeLanguageCodes: ['en-IN', 'en-US'],
  enableAutomaticPunctuation: true,
  enableWordTimeOffsets: true,
  enableWordConfidence: true,
  // ğŸ”¥ Noise suppression
  useEnhanced: true,
  model: 'latest_long',
  // ğŸ”¥ Better for noisy environments
  audioChannelCount: 1,
  enableSeparateRecognitionPerChannel: false,
  metadata: {
    interactionType: 'VOICE_COMMAND',
    microphoneDistance: 'NEARFIELD',
    originalMediaType: 'AUDIO',
    recordingDeviceType: 'SMARTPHONE'
  }
}

// Process audio
const [response] = await client.recognize({
  audio: { content: audioBytes },
  config: config
})

const transcription = response.results
  .map(result => result.alternatives[0].transcript)
  .join('\n')
```

**Pros:**

- ğŸ¯ Best accuracy (95%+ for English, 90%+ for Hindi)
- ğŸ”‡ Built-in noise suppression
- ğŸŒ 120+ languages with automatic detection
- ğŸ“Š Word-level confidence scores
- ğŸ”¤ Automatic punctuation
- ğŸ’° Free tier: 60 minutes/month

**Cons:**

- ğŸ’µ Paid beyond free tier ($0.006/15 seconds)
- ğŸ”‘ Requires API key management
- ğŸŒ Needs internet connection

**Best For:** Production apps, high accuracy requirements

---

### Option 2: Azure Speech Service

```javascript
// Installation
npm install microsoft-cognitiveservices-speech-sdk

// Implementation
import * as sdk from 'microsoft-cognitiveservices-speech-sdk'

const speechConfig = sdk.SpeechConfig.fromSubscription(
  process.env.AZURE_SPEECH_KEY,
  process.env.AZURE_SPEECH_REGION
)

speechConfig.speechRecognitionLanguage = 'hi-IN'
// ğŸ”¥ Noise suppression
speechConfig.setProperty(
  sdk.PropertyId.Speech_LogFilename,
  'speech-log.txt'
)

const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput()
const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig)

recognizer.recognizeOnceAsync(result => {
  if (result.reason === sdk.ResultReason.RecognizedSpeech) {
    console.log(`Transcript: ${result.text}`)
    console.log(`Confidence: ${result.properties.getProperty(
      sdk.PropertyId.SpeechServiceResponse_JsonResult
    )}`)
  }
})
```

**Pros:**

- ğŸ¯ Excellent accuracy (94%+)
- ğŸ”‡ Advanced noise cancellation
- ğŸ—£ï¸ Speaker recognition
- ğŸ›ï¸ Custom voice models
- ğŸ“Š Real-time transcription
- ğŸ’° Free tier: 5 audio hours/month

**Cons:**

- ğŸ’µ Expensive beyond free tier ($1/hour)
- ğŸ¢ Microsoft ecosystem
- ğŸ“š Complex setup

**Best For:** Enterprise applications, custom models

---

### Option 3: Deepgram â­ Best Value

```javascript
// Installation
npm install @deepgram/sdk

// Implementation
import { Deepgram } from '@deepgram/sdk'

const deepgram = new Deepgram(process.env.DEEPGRAM_API_KEY)

const response = await deepgram.transcription.preRecorded({
  buffer: audioBuffer,
  mimetype: 'audio/wav'
}, {
  punctuate: true,
  language: 'hi',
  // ğŸ”¥ Noise reduction
  model: 'nova-2',
  smart_format: true,
  diarize: false,
  // ğŸ”¥ Hinglish support
  tier: 'enhanced'
})

const transcript = response.results.channels[0].alternatives[0].transcript
const confidence = response.results.channels[0].alternatives[0].confidence
```

**Pros:**

- âš¡ Fastest processing (< 1 second)
- ğŸ¯ Good accuracy (90%+)
- ğŸ’° Most affordable ($0.0043/minute)
- ğŸ‡®ğŸ‡³ Good Hinglish support
- ğŸ”‡ Decent noise handling
- ğŸ†“ $200 free credit

**Cons:**

- ğŸ†• Newer service (less mature)
- ğŸ“š Smaller ecosystem
- ğŸŒ Fewer languages than Google

**Best For:** Startups, Hinglish, cost-sensitive apps

---

### Option 4: AssemblyAI

```javascript
// Installation
npm install assemblyai

// Implementation
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: process.env.ASSEMBLYAI_API_KEY
})

const transcript = await client.transcripts.create({
  audio_url: audioUrl,
  language_code: 'hi',
  // ğŸ”¥ Noise reduction
  audio_start_from: 0,
  audio_end_at: 2147483647,
  punctuate: true,
  format_text: true,
  // ğŸ”¥ Enhanced accuracy
  dual_channel: false,
  webhook_url: 'https://your-webhook.com'
})

console.log(transcript.text)
console.log(transcript.confidence)
```

**Pros:**

- ğŸ¯ High accuracy (92%+)
- ğŸ¤– Built-in NLP features
- ğŸ·ï¸ Auto-categorization
- ğŸ“Š Sentiment analysis
- ğŸ’° Simple pricing ($0.00025/second)

**Cons:**

- ğŸŒ Limited Indian language support
- ğŸ’µ No free tier (pay per use)
- ğŸŒ Slower processing

**Best For:** Apps needing NLP features

---

## Noise Filtering Techniques

### 1. Web Audio API Preprocessing (Current Implementation)

```javascript
// Client-side noise reduction
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

// High-pass filter (remove low-frequency noise)
const highPassFilter = audioContext.createBiquadFilter();
highPassFilter.type = "highpass";
highPassFilter.frequency.value = 200; // Hz

// Compressor (normalize volume)
const compressor = audioContext.createDynamicsCompressor();
compressor.threshold.value = -50; // dB
compressor.knee.value = 40;
compressor.ratio.value = 12;
compressor.attack.value = 0;
compressor.release.value = 0.25;

// Noise gate (remove background noise)
const noiseGate = audioContext.createGain();
noiseGate.gain.value = 0;

// Connect: source â†’ filter â†’ compressor â†’ gate â†’ destination
source.connect(highPassFilter);
highPassFilter.connect(compressor);
compressor.connect(noiseGate);
noiseGate.connect(audioContext.destination);
```

**Pros:**

- âœ… Client-side (privacy)
- âœ… Real-time
- âœ… No server load
- âœ… Free

**Cons:**

- âš ï¸ Limited effectiveness
- âš ï¸ Browser-dependent
- âš ï¸ CPU intensive on mobile

---

### 2. Server-side Processing with FFmpeg

```javascript
// Backend noise reduction
import ffmpeg from "fluent-ffmpeg";

function reduceNoise(inputFile, outputFile) {
  return new Promise((resolve, reject) => {
    ffmpeg(inputFile)
      // High-pass filter
      .audioFilters("highpass=f=200")
      // Noise reduction
      .audioFilters("anlmdn=s=0.01")
      // Normalize audio
      .audioFilters("loudnorm=I=-16:LRA=11:TP=-1.5")
      // Compress dynamic range
      .audioFilters("acompressor=threshold=-20dB:ratio=4:attack=5:release=50")
      .output(outputFile)
      .on("end", resolve)
      .on("error", reject)
      .run();
  });
}

// Usage
await reduceNoise("noisy-audio.wav", "clean-audio.wav");
```

**Pros:**

- âœ… Very effective
- âœ… Professional quality
- âœ… Customizable

**Cons:**

- âš ï¸ Server load
- âš ï¸ Processing time
- âš ï¸ Storage needed

---

### 3. RNNoise (Deep Learning)

```javascript
// Installation
npm install rnnoise-wasm

// Implementation
import { RNNoise } from 'rnnoise-wasm'

async function cleanAudio(audioBuffer) {
  const rnnoise = await RNNoise.load()

  // Process audio in chunks
  const cleanBuffer = rnnoise.process(audioBuffer)

  return cleanBuffer
}
```

**Pros:**

- âœ… ML-powered (very effective)
- âœ… Real-time capable
- âœ… Open-source

**Cons:**

- âš ï¸ WebAssembly required
- âš ï¸ CPU intensive
- âš ï¸ Setup complexity

---

## Implementation Roadmap

### Phase 1: Immediate (No Code Change) âœ…

- [x] User guidance (speak clearly, quiet place)
- [x] Visual feedback (audio quality indicator)
- [x] Retry mechanism
- [x] Better error messages

### Phase 2: Short-term (1-2 weeks)

- [ ] Basic Web Audio API filters
  ```javascript
  // Add to VoiceExpenseEntry.js
  const applyNoiseReduction = (stream) => {
    // Implementation from above
  };
  ```

### Phase 3: Medium-term (1-2 months)

- [ ] Migrate to Deepgram or Google Cloud
  - Cost: ~$50-100/month for 1000 users
  - Benefit: 20-30% accuracy improvement
  - Setup: 2-3 days

### Phase 4: Long-term (3-6 months)

- [ ] Implement RNNoise for client-side preprocessing
- [ ] Add FFmpeg for server-side batch processing
- [ ] Train custom model on user corrections

---

## Cost Comparison (1000 users, 5 voice entries/day)

| Service                      | Free Tier     | Cost/Month | Accuracy | Noise Handling |
| ---------------------------- | ------------- | ---------- | -------- | -------------- |
| **Web Speech API** (Current) | âœ… Unlimited  | $0         | 80-85%   | âš ï¸ Poor        |
| **Deepgram**                 | $200 credit   | ~$60       | 90-92%   | âœ… Good        |
| **Google Cloud**             | 60 min/month  | ~$150      | 93-95%   | âœ… Excellent   |
| **Azure Speech**             | 5 hours/month | ~$200      | 92-94%   | âœ… Excellent   |
| **AssemblyAI**               | None          | ~$75       | 90-92%   | âœ… Good        |

**Calculation:** 1000 users Ã— 5 entries/day Ã— 10 seconds/entry Ã— 30 days = 41,667 minutes/month

---

## Recommendation

### For MVP/Testing (Current) âœ…

```
Web Speech API + Enhanced Logic
- Cost: $0
- Accuracy: 85%+
- Good enough for launch
```

### For Production (Next 2 months) â­

```
Deepgram API
- Cost: $60/month
- Accuracy: 90%+
- Best value for money
- Easy migration
```

### For Scale (6+ months)

```
Google Cloud Speech-to-Text
- Cost: $150/month
- Accuracy: 95%+
- Enterprise-ready
- Best overall
```

---

## Migration Guide: Web Speech â†’ Deepgram

### Step 1: Install SDK

```bash
npm install @deepgram/sdk
```

### Step 2: Update Environment

```bash
# .env.local
DEEPGRAM_API_KEY=your_api_key_here
```

### Step 3: Update API Route

```javascript
// app/api/voice/transcribe/route.js
import { Deepgram } from "@deepgram/sdk";

export async function POST(request) {
  const { audioBlob } = await request.json();

  const deepgram = new Deepgram(process.env.DEEPGRAM_API_KEY);

  const response = await deepgram.transcription.preRecorded(
    {
      buffer: Buffer.from(audioBlob),
      mimetype: "audio/webm",
    },
    {
      punctuate: true,
      language: "hi",
      model: "nova-2",
      smart_format: true,
    }
  );

  const transcript = response.results.channels[0].alternatives[0].transcript;
  const confidence = response.results.channels[0].alternatives[0].confidence;

  return Response.json({ transcript, confidence });
}
```

### Step 4: Update Frontend

```javascript
// components/voice/VoiceExpenseEntry.js
const processAudio = async (audioBlob) => {
  // Send to new API
  const response = await fetch("/api/voice/transcribe", {
    method: "POST",
    body: JSON.stringify({ audioBlob }),
  });

  const { transcript, confidence } = await response.json();

  // Continue with existing logic
  processVoiceInput(transcript);
};
```

**Estimated Migration Time:** 4-6 hours  
**Testing Time:** 2-3 days  
**Rollout Strategy:** A/B test 10% â†’ 50% â†’ 100%

---

## Testing Checklist

### Before Migration

- [ ] Test current accuracy (baseline)
- [ ] Document common failure cases
- [ ] Measure latency
- [ ] Calculate costs

### After Migration

- [ ] A/B test accuracy improvement
- [ ] Monitor latency changes
- [ ] Track user satisfaction
- [ ] Verify cost predictions

### Success Criteria

- âœ… Accuracy > 90%
- âœ… Latency < 3 seconds
- âœ… Cost < $100/month
- âœ… User satisfaction +20%

---

**Last Updated:** October 16, 2025  
**Status:** Ready for Phase 2 Implementation  
**Recommended Next Step:** Implement basic Web Audio API filters
